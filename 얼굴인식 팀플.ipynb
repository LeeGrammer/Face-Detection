{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56148527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, dlib, sys\n",
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59d8eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_transparent(background_img, img_to_overlay_t, x, y, overlay_size=None):\n",
    "    bg_img = background_img.copy()\n",
    "    # convert 3 channels to 4 channels\n",
    "    if bg_img.shape[2] == 3:\n",
    "        bg_img = cv2.cvtColor(bg_img, cv2.COLOR_BGR2BGRA)\n",
    "\n",
    "    if overlay_size is not None:\n",
    "        img_to_overlay_t = cv2.resize(img_to_overlay_t.copy(), overlay_size)\n",
    "\n",
    "    if img_to_overlay_t.shape[2] != 4:\n",
    "        raise ValueError(\"img_to_overlay_t에 알파 채널이 없습니다.\")\n",
    "        \n",
    "    b, g, r, a = cv2.split(img_to_overlay_t)\n",
    "    mask = cv2.medianBlur(a, 5)\n",
    "\n",
    "    h, w = img_to_overlay_t.shape[:2]\n",
    "    x1, y1 = int(x-w / 2), int(y-h / 2)\n",
    "    x2, y2 = x1 + w, y1+h\n",
    "    \n",
    "    if x1 < 0 or y1 < 0 or x2 > bg_img.shape[1] or y2 > bg_img.shape[0]:\n",
    "        return bg.img\n",
    "    \n",
    "    roi = bg_img[y1:y2, x1:x2]\n",
    "    \n",
    "    if roi.shape[:2] != mask.shape[:2]:\n",
    "        mask = cv2.resize(mask, (roi.shape[1], roi.shape[0]))\n",
    "        img_to_overlay_t = cv2.resize(img_to_overlay_t, (roi.shape[1], roi.shape[0]))\n",
    "        \n",
    "    if roi.dtype != np.uint8:\n",
    "        roi = roi.astype(np.uint8)\n",
    "    if mask.dtype != np.uint8:\n",
    "        mask = mask.astype(np.uint8)\n",
    "    if img_to_overlay_t.dtype != np.uint8:\n",
    "        img_to_overlay_t = img_to_overlay_t.astype(np.uint8)\n",
    "\n",
    "    img1_bg = cv2.bitwise_and(roi.copy(), roi.copy(), mask=cv2.bitwise_not(mask))\n",
    "    img2_fg = cv2.bitwise_and(img_to_overlay_t, img_to_overlay_t, mask=mask)\n",
    "\n",
    "    bg_img[y1:y2, x1:x2] = cv2.add(img1_bg, img2_fg)\n",
    "\n",
    "    return cv2.cvtColor(bg_img, cv2.COLOR_BGRA2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3baad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# face detector\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "# 68 points predictor\n",
    "predictor = dlib.shape_predictor(\"shape_predictor_68_face_landmarks.dat\")\n",
    "cap = cv2.VideoCapture(0)\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "ryan = cv2.imread(\"ryan_transparent.png\", cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "# distinguish points in each area of the face\n",
    "all = list(range(0, 68))\n",
    "jawline = list(range(0, 17))\n",
    "right_eyebrow = list(range(17, 22))\n",
    "left_eyebrow = list(range(22, 27))\n",
    "nose = list(range(27, 36))\n",
    "right_eye = list(range(36, 42))\n",
    "left_eye = list(range(42, 48))\n",
    "mouth_outline = list(range(48, 61))\n",
    "mouth_inline = list(range(61, 68))\n",
    "\n",
    "index = all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85f71d34",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 49\u001b[0m\n\u001b[1;32m     47\u001b[0m             cv2\u001b[38;5;241m.\u001b[39mrectangle(frame, (x, y), (x \u001b[38;5;241m+\u001b[39m w, y \u001b[38;5;241m+\u001b[39m h), (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m), \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     48\u001b[0m         face_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(bottom_right \u001b[38;5;241m-\u001b[39m top_left)\n\u001b[0;32m---> 49\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43moverlay_transparent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mryan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverlay_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mface_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mface_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# show the frame\u001b[39;00m\n\u001b[1;32m     51\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult\u001b[39m\u001b[38;5;124m'\u001b[39m, result)\n",
      "Cell \u001b[0;32mIn[5], line 21\u001b[0m, in \u001b[0;36moverlay_transparent\u001b[0;34m(background_img, img_to_overlay_t, x, y, overlay_size)\u001b[0m\n\u001b[1;32m     18\u001b[0m x2, y2 \u001b[38;5;241m=\u001b[39m x1 \u001b[38;5;241m+\u001b[39m w, y1\u001b[38;5;241m+\u001b[39mh\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x1 \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m y1 \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m x2 \u001b[38;5;241m>\u001b[39m bg_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m y2 \u001b[38;5;241m>\u001b[39m bg_img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbg\u001b[49m\u001b[38;5;241m.\u001b[39mimg\n\u001b[1;32m     23\u001b[0m roi \u001b[38;5;241m=\u001b[39m bg_img[y1:y2, x1:x2]\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m roi\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m!=\u001b[39m mask\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m2\u001b[39m]:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bg' is not defined"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "\n",
    "    # read the frame\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:\n",
    "        dst = cv2.flip(frame, 1)\n",
    "\n",
    "        # convert to RGB\n",
    "        gray = cv2.cvtColor(dst, cv2.COLOR_BGR2GRAY)\n",
    "        # detect faces in the frame\n",
    "        detect = detector(gray, 1)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "        \n",
    "        result = dst.copy()\n",
    "        \n",
    "        if detect:\n",
    "            for face in detect:\n",
    "                # find 68 points on the face\n",
    "                shape = predictor(dst, face)\n",
    "                lists = np.array([[p.x, p.y] for p in shape.parts()])\n",
    "#                 lists = []\n",
    "#                 for p in shape.parts():\n",
    "#                     lists.append([p.x, p.y])\n",
    "\n",
    "#                 lists = np.array(lists)\n",
    "\n",
    "                top_left = np.min(lists, axis=0)\n",
    "                bottom_right = np.max(lists, axis=0)\n",
    "\n",
    "                center_x, center_y = np.mean(lists, axis=0).astype(np.int32)\n",
    "\n",
    "                for s in lists:\n",
    "                    cv2.circle(frame, center=tuple(s), radius=1, color=(255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "\n",
    "                cv2.circle(frame, center=tuple(top_left), radius=1, color=(255, 0, 0), thickness=2, lineType=cv2.LINE_AA)\n",
    "                cv2.circle(frame, center=tuple(bottom_right), radius=1, color=(255, 0, 0), thickness=2,\n",
    "                           lineType=cv2.LINE_AA)\n",
    "\n",
    "                cv2.circle(frame, center=tuple((center_x, center_y)), radius=1, color=(0, 0, 255), thickness=2,\n",
    "                           lineType=cv2.LINE_AA)\n",
    "                for i, point in enumerate(lists[index]):\n",
    "                    points = (point[0], point[1])\n",
    "                    cv.circle(frame, points, 2, (0, 255, 0), -1)\n",
    "\n",
    "                for (x, y, w, h) in faces:\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 0, 255), 2)\n",
    "                face_size = max(bottom_right - top_left)\n",
    "                result = overlay_transparent(dst, ryan, center_x, center_y, overlay_size=(face_size, face_size))\n",
    "            # show the frame\n",
    "        cv2.imshow('result', result)\n",
    "\n",
    "        # if the 'q' key was pressed, break from the loop\n",
    "        if cv2.waitKey(1) == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1) # 이벤트 루프 갱신 -> 창이 완전히 닫힘 보장"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
